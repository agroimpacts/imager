{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2bf2bc1-422f-4829-9fb1-0a97ac300874",
   "metadata": {},
   "source": [
    "## Mosaick score maps\n",
    "\n",
    "Test out code to mosaick score maps for version 2 maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb0560c-29e7-4186-bc28-d581e1d93ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import boto3\n",
    "from rasterio.plot import show\n",
    "import os\n",
    "from rio_cogeo.cogeo import cog_translate\n",
    "from rio_cogeo.profiles import cog_profiles\n",
    "import re\n",
    "from subprocess import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4beeff-9f00-436f-b6ed-00c757eacee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects(s3_resource, bucket, prefix, suffix=None):\n",
    "    \"\"\"\n",
    "    Get list of keys in an S3 bucket, filtering by prefix and suffix. Function\n",
    "    developed by Kaixi Zhang as part of AWS_S3 class and adapted slightly here.\n",
    "    This function retrieves all matching objects, and is not subject to the 1000\n",
    "    item limit.\n",
    "        Params:\n",
    "            s3_resource (object): A boto3 s3 resource object\n",
    "            bucket (str): Name of s3 bucket to list\n",
    "            prefix (str): Prefix within bucket to search\n",
    "            suffix (str, list): Optional string or string list of file endings\n",
    "        Returns:\n",
    "            List of s3 keys\n",
    "    \"\"\"\n",
    "    keys = []\n",
    "    if s3_resource is not None:\n",
    "        s3_bucket = s3_resource.Bucket(bucket)\n",
    "        for obj in s3_bucket.objects.filter(Prefix=prefix):\n",
    "            # if no suffix given, add all objects with the prefix\n",
    "            if suffix is None:\n",
    "                keys.append(str(obj.key))\n",
    "            else:\n",
    "                # add all objects that ends with the given suffix\n",
    "                if isinstance(suffix, list):\n",
    "                    for _suffix in suffix:\n",
    "                        if obj.key.endswith(_suffix):\n",
    "                            keys.append(str(obj.key))\n",
    "                            break\n",
    "                else:\n",
    "                    # suffix is a single string\n",
    "                    if obj.key.endswith(suffix):\n",
    "                        keys.append(str(obj.key))\n",
    "    else:\n",
    "        print\n",
    "        'Warning: please first create an s3 resource'\n",
    "    return keys\n",
    "\n",
    "# Write mosaic to s3\n",
    "def mosaic_to_s3(images, bucket, output_key, s3_client):\n",
    "\n",
    "    # merge\n",
    "    print('Merging images')\n",
    "    array, out_trans = merge(images) \n",
    "\n",
    "    # profile \n",
    "    profile = images[0].profile\n",
    "    profile['transform'] = out_trans\n",
    "    profile['height'] = array.shape[1]\n",
    "    profile['width'] = array.shape[2]\n",
    "    profile['driver'] = 'GTiff'\n",
    "    profile['compress'] = \"lzw\"\n",
    "    profile['tiled'] = True\n",
    "    \n",
    "    # profile['dtype'] = 'int8'\n",
    "    \n",
    "    \n",
    "    print('Writing to S3')\n",
    "    # write to S3 (should be local, but don't have disk space)\n",
    "    with MemoryFile() as mem_file:\n",
    "        with mem_file.open(**profile) as dataset:\n",
    "            dataset.write(array)\n",
    "\n",
    "        # to s3 \n",
    "        s3_client.upload_fileobj(mem_file, bucket, output_key)\n",
    "\n",
    "\n",
    "# Mosaick local\n",
    "def mosaic(images, fileout):\n",
    "\n",
    "    # merge\n",
    "    print('Merging images')\n",
    "    array, out_trans = merge(images) \n",
    "\n",
    "    # profile \n",
    "    profile = images[0].profile\n",
    "    profile['transform'] = out_trans\n",
    "    profile['height'] = array.shape[1]\n",
    "    profile['width'] = array.shape[2]\n",
    "    profile['driver'] = 'GTiff'\n",
    "    profile['compress'] = \"lzw\"\n",
    "    # profile['tiled'] = True\n",
    "    # profile['dtype'] = 'int8'\n",
    "    \n",
    "    print('Writing to disk')\n",
    "    # write to local\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(fileout, 'w', **profile) as dst:\n",
    "            dst.write(array)\n",
    "            \n",
    "    except:\n",
    "        print('Write failure for {}'.format(fileout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568826c-942d-485a-bb2a-24d59dc7bf2b",
   "metadata": {},
   "source": [
    "### Get items in bucket\n",
    "\n",
    "Set up paths and necessary credentials to read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a81e69-147c-4bd5-8c40-1c1824904888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = '***REMOVED***'\n",
    "prefix_base = 'DL/Result/semantic_segmentation/boka/relabeller/coarse_as_benchmark/' + \\\n",
    "    'balanced_tversky_g09/new/d3500/refine_freeze58/ep150/predict/'\n",
    "prefixes = ['{}predict_{}/Score_1/'.format(prefix_base, i) for i in range(1, 17)]\n",
    "\n",
    "# set up output names and directories\n",
    "# s3 location\n",
    "output_prefix = 'maps/ghana/score_1/'\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "\n",
    "# local directory\n",
    "local_dir = os.path.join(ROOT, 'imager/planet/catalog/')\n",
    "\n",
    "# filenames\n",
    "output_images = ['ghana_score1_{}_v0_1.tif'.format(i) for i in range(1, 17)]\n",
    "# output_images\n",
    "# local_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca036608-7b88-490d-ba07-e4020fec3e13",
   "metadata": {},
   "source": [
    "### Create mosaic\n",
    "\n",
    "Going through just one prefix (AOI) as a test\n",
    "\n",
    "#### List of input images\n",
    "\n",
    "Get keys from S3 and set up output filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "039f7b8b-8138-4113-8b8b-b20552e6fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = boto3.client('s3')\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3') # client, for later use\n",
    "keys = list_objects(s3, bucket, prefixes[0], 'tif')\n",
    "keys_full = ['s3://***REMOVED***/%s' % (key) for key in keys]\n",
    "\n",
    "# output file names\n",
    "local_file = '{}{}'.format(local_dir, output_images[0])\n",
    "cog_name = re.sub('.tif', '_cog.tif', output_images[0])\n",
    "local_cog_file = '{}{}'.format(local_dir, cog_name)\n",
    "output_key = '{}{}'.format(output_prefix, cog_name) # COG to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d35e8a-d7b7-4ef5-b5a0-19abdfc0a1fe",
   "metadata": {},
   "source": [
    "#### Read in images from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79d3bfa7-803b-47d7-9cf0-10621653c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [rasterio.open(key) for key in keys_full]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dfb83e-a3b4-4708-97d7-f88e3ef35e39",
   "metadata": {},
   "source": [
    "#### Create mosaic\n",
    "\n",
    "There is a way to do this straight onto S3 as well, but opting for local write (to EBS volume) to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6a6716b-e5b4-4518-b700-4b9dd1814807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging images\n",
      "Writing to disk\n"
     ]
    }
   ],
   "source": [
    "# mosaic_to_s3(images, bucket, output_key, s3_client)\n",
    "mosaic(images, local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542cda1-8f49-426d-8233-acdb7c0c804d",
   "metadata": {},
   "source": [
    "#### Create COG\n",
    "\n",
    "System call to `rio cogeo create`. Replace with python API and `cog_translate` in the long run, following approach [here](https://cogeotiff.github.io/rio-cogeo/API/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2441368-4613-4271-9761-920ec5a3969d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reading input: /home/ubuntu/projects/imager/planet/catalog/ghana_score1_1_v0_1.tif\\nAdding overviews...\\nUpdating dataset tags...\\nWriting output to: /home/ubuntu/projects/imager/planet/catalog/ghana_score1_1_v0_1_cog.tif\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = ['rio', 'cogeo', 'create', '--nodata', '-128', local_file, local_cog_file]\n",
    "p = run(cmd, capture_output=True)\n",
    "p.stderr.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527024e-5e49-4891-9724-649ceed5ccb0",
   "metadata": {},
   "source": [
    "#### Validate COG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98624462-e9d8-4c70-af73-4d757901f0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/projects/imager/planet/catalog/ghana_score1_1_v0_1_cog.tif is a valid cloud optimized GeoTIFF\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subprocess.Popen(['rio', 'cogeo', 'validate', output_cog], stderr=subprocess.STDOUT)\n",
    "cmd = ['rio', 'cogeo', 'validate', local_cog_file]\n",
    "p = run(cmd, capture_output=True)\n",
    "p.stdout.decode()\n",
    "# p.stderr.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977d0b1-5c53-4578-bf05-833a27699205",
   "metadata": {},
   "source": [
    "#### Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf4032d1-d36d-4095-b271-7338e7acc36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file(local_cog_file, bucket, output_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73846225-b275-4083-9800-eaaedd6e4d64",
   "metadata": {},
   "source": [
    "## Process all\n",
    "\n",
    "Once working, run in loop to process AOIs all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7621c6a-8c13-48d7-86a4-ae81245c0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = '***REMOVED***'\n",
    "prefix_base = 'DL/Result/semantic_segmentation/boka/relabeller/coarse_as_benchmark/' + \\\n",
    "    'balanced_tversky_g09/new/d3500/refine_freeze58/ep150/predict/'\n",
    "\n",
    "# local directory\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "local_dir = os.path.join(ROOT, 'imager/planet/catalog/')\n",
    "\n",
    "# resource/client\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3') # client, for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7fce4c-b690-4a9d-908c-ff64e90a8393",
   "metadata": {},
   "source": [
    "#### Creating mosaics/COGs in loop\n",
    "\n",
    "Run on a larger memory capacity instance. This almost got all the way through 16 AOIs using a t2.xlarge, but memory failure on one required 32 GB ram and and an r5.2xlarge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf8e55-d528-4f33-aa32-adc6922e6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting keys DL/Result/semantic_segmentation/boka/relabeller/coarse_as_benchmark/balanced_tversky_g09/new/d3500/refine_freeze58/ep150/predict/predict_13/Score_1/\n",
      "Reading images from DL/Result/semantic_segmentation/boka/relabeller/coarse_as_benchmark/balanced_tversky_g09/new/d3500/refine_freeze58/ep150/predict/predict_13/Score_1/\n",
      "Creating mosaic /home/ubuntu/projects/imager/planet/catalog/ghana_score1_13_v0_1.tif\n",
      "Merging images\n",
      "Writing to disk\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1, 17): \n",
    "# for i in range(13, 14): \n",
    "for i in range(14, 17): \n",
    "    \n",
    "#     i = 13\n",
    "    # set up file paths\n",
    "    input_prefix = '{}predict_{}/Score_1/'.format(prefix_base, i)\n",
    "    output_prefix = 'maps/ghana/score_1/'  \n",
    "    output_image = 'ghana_score1_{}_v0_1.tif'.format(i)\n",
    "    \n",
    "    # output files. Only COG goes to S3\n",
    "    local_file = '{}{}'.format(local_dir, output_image)\n",
    "    cog_name = re.sub('.tif', '_cog.tif', output_image)\n",
    "    local_cog_file = '{}{}'.format(local_dir, cog_name)\n",
    "    output_key = '{}{}'.format(output_prefix, cog_name) # COG to S3\n",
    "\n",
    "    # image keys\n",
    "    print(\"Getting keys {}\".format(input_prefix))\n",
    "    keys = list_objects(s3, bucket, input_prefix, 'tif')\n",
    "    keys_full = ['s3://***REMOVED***/%s' % (key) for key in keys]\n",
    "    \n",
    "    # Read in images\n",
    "    print(\"Reading images from {}\".format(input_prefix))\n",
    "    images = [rasterio.open(key) for key in keys_full]\n",
    "    \n",
    "    # create local mosaic\n",
    "    print(\"Creating mosaic {}\".format(local_file))\n",
    "    mosaic(images, local_file)\n",
    "    \n",
    "    # create COG\n",
    "    print(\"Creating cog from {}\".format(local_file))\n",
    "    cmd = ['rio', 'cogeo', 'create', '--nodata', '-128', local_file, local_cog_file]\n",
    "    p = run(cmd, capture_output=True)\n",
    "    print(p.stderr.decode())\n",
    "    \n",
    "    # validate COG\n",
    "    print(\"Validating {}\".format(local_cog_file))\n",
    "    cmd = ['rio', 'cogeo', 'validate', local_cog_file]\n",
    "    p = run(cmd, capture_output=True)\n",
    "    print(p.stdout.decode())\n",
    "    \n",
    "    # upload to S3\n",
    "    print(\"Uploading {} to S3\".format(cog_name))\n",
    "    s3_client.upload_file(local_cog_file, bucket, output_key)\n",
    "    \n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
